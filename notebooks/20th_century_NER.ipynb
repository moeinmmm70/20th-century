{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "029739a0-ed92-42ec-be1e-83cfe1698f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d928fbb-3d3a-44d8-a058-b42663f2b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\moein\\20th-century\\data\\raw\\key_events_20th_century_raw.txt\", \"r\", errors=\"ignore\") as file:\n",
    "    text = file.read().replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f879ba4a-99be-45c4-96dc-c9540f98785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters like em-dashes, ellipses\n",
    "text = re.sub(r\"[^A-Za-z0-9,.!?;:'\\\"\\s]\", \" \", text)\n",
    "\n",
    "# Normalize multiple spaces\n",
    "text = re.sub(r\"\\s+\", \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78829cfe-5fda-4148-bf61-27e8e51c48cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\moein\\20th-century\\data\\raw\\20th_century_cleaned.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43c50fd8-c8a3-4c89-b98f-be2888936e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a NER object\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcadf569-f61a-4178-90bb-23d4f521c771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOURCE: https: en.wikipedia.org wiki Key event...</td>\n",
       "      <td>[the 20th century, 2025, 10:45:33, UTC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wikipedia content is under CC BY SA 4.0.</td>\n",
       "      <td>[Wikipedia, SA 4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Historic events in the 20th century World at t...</td>\n",
       "      <td>[the 20th century, the beginning of the centur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The war in Europe Blitzkrieg Operation Barbaro...</td>\n",
       "      <td>[Europe, Operation Overlord Final]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The war in the Pacific Japanese Expansion Alli...</td>\n",
       "      <td>[the Pacific Japanese Expansion, The Holocaust...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  SOURCE: https: en.wikipedia.org wiki Key event...   \n",
       "1           Wikipedia content is under CC BY SA 4.0.   \n",
       "2  Historic events in the 20th century World at t...   \n",
       "3  The war in Europe Blitzkrieg Operation Barbaro...   \n",
       "4  The war in the Pacific Japanese Expansion Alli...   \n",
       "\n",
       "                                            entities  \n",
       "0            [the 20th century, 2025, 10:45:33, UTC]  \n",
       "1                                [Wikipedia, SA 4.0]  \n",
       "2  [the 20th century, the beginning of the centur...  \n",
       "3                 [Europe, Operation Overlord Final]  \n",
       "4  [the Pacific Japanese Expansion, The Holocaust...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split sentence entities\n",
    "df_sentences = []\n",
    "for sent in doc.sents:\n",
    "    entity_list = [ent.text for ent in sent.ents]\n",
    "    df_sentences.append({\"sentence\": sent.text, \"entities\": entity_list})\n",
    "\n",
    "df_sentences = pd.DataFrame(df_sentences)\n",
    "df_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f753b2e2-280d-4069-900c-401bde870bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the countries list\n",
    "countries_df = pd.read_csv(\n",
    "    r\"C:\\Users\\moein\\20th-century\\data\\reference\\countries_list_20th_century_1.5.csv\"\n",
    ")\n",
    "\n",
    "def filter_entities(ent_list, country_df):\n",
    "    return [ent for ent in ent_list if ent in list(country_df['country_name'])]\n",
    "\n",
    "# Apply filter to keep only entities that are countries\n",
    "df_sentences['country_entities'] = df_sentences['entities'].apply(\n",
    "    lambda x: filter_entities(x, countries_df)\n",
    ")\n",
    "\n",
    "# Keep only rows with at least one recognized country\n",
    "df_sentences_filtered = df_sentences[df_sentences['country_entities'].map(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "145fc720-74b3-4646-8c63-5448ce0e2bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 572\n",
      "Rows w/ any entities: 518\n",
      "Rows w/ country entities: 0\n",
      "                                            sentence  \\\n",
      "0  SOURCE: https: en.wikipedia.org wiki Key event...   \n",
      "1           Wikipedia content is under CC BY SA 4.0.   \n",
      "2  Historic events in the 20th century World at t...   \n",
      "\n",
      "                                            entities country_entities  \n",
      "0            [the 20th century, 2025, 10:45:33, UTC]               []  \n",
      "1                                [Wikipedia, SA 4.0]               []  \n",
      "2  [the 20th century, the beginning of the centur...               []  \n",
      "0              [the 20th century, 2025, 10:45:33, UTC]\n",
      "1                                  [Wikipedia, SA 4.0]\n",
      "2    [the 20th century, the beginning of the centur...\n",
      "3                   [Europe, Operation Overlord Final]\n",
      "4    [the Pacific Japanese Expansion, The Holocaust...\n",
      "5                       [the Cold War, the Space Race]\n",
      "6                            [the 21st century, today]\n",
      "7                                   [the 20th century]\n",
      "8                              [The 1900s, the decade]\n",
      "9                             [1914, the Panama Canal]\n",
      "Name: entities, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Total sentences:\", len(df_sentences))\n",
    "print(\"Rows w/ any entities:\", (df_sentences['entities'].map(len) > 0).sum())\n",
    "print(\"Rows w/ country entities:\", (df_sentences['country_entities'].map(len) > 0).sum())\n",
    "print(df_sentences.head(3))\n",
    "print(df_sentences['entities'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23d44bd5-25af-4c0e-a376-0d28ad964784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after normalization: 137\n"
     ]
    }
   ],
   "source": [
    "def norm(s: str) -> str:\n",
    "    # lower, remove dots/commas, collapse spaces\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^\\w\\s-]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Build a fast lookup set from your country list\n",
    "countries_df = pd.read_csv(r\"C:\\Users\\moein\\20th-century\\data\\reference\\countries_list_20th_century_1.5.csv\")\n",
    "\n",
    "# If your CSV has a column 'country_name'\n",
    "country_names = set(norm(x) for x in countries_df['country_name'].astype(str))\n",
    "\n",
    "# Add common aliases (extend as needed)\n",
    "aliases = {\n",
    "    \"u s\": \"united states\",\n",
    "    \"u s a\": \"united states\",\n",
    "    \"us\": \"united states\",\n",
    "    \"usa\": \"united states\",\n",
    "    \"u k\": \"united kingdom\",\n",
    "    \"uk\": \"united kingdom\",\n",
    "    \"great britain\": \"united kingdom\",\n",
    "    \"britain\": \"united kingdom\",\n",
    "    \"russia\": \"russian federation\",\n",
    "    \"soviet union\": \"ussr\",\n",
    "    \"ussr\": \"ussr\",\n",
    "    \"iran\": \"iran\",\n",
    "    \"pr china\": \"china\",\n",
    "    \"peoples republic of china\": \"china\",\n",
    "}\n",
    "# Merge aliases into the lookup\n",
    "country_names |= set(aliases.values())\n",
    "\n",
    "def normalize_and_map(ent: str) -> str | None:\n",
    "    n = norm(ent)\n",
    "    if n in aliases: n = aliases[n]\n",
    "    return n if n in country_names else None\n",
    "\n",
    "# Rebuild country_entities with normalization\n",
    "def filter_entities(ent_list):\n",
    "    out = []\n",
    "    for ent in ent_list:\n",
    "        mapped = normalize_and_map(ent)\n",
    "        if mapped:\n",
    "            out.append(mapped.title())  # title-case for readability\n",
    "    return out\n",
    "\n",
    "df_sentences['country_entities'] = df_sentences['entities'].apply(filter_entities)\n",
    "df_sentences_filtered = df_sentences[df_sentences['country_entities'].map(len) > 0].copy()\n",
    "df_sentences_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Rows after normalization:\", len(df_sentences_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "116a09bb-5922-4349-894c-16debec417e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Greece</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Ussr</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Italy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Cape Verde</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Mozambique</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Canada</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Japan</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source       target  value\n",
       "0    Albania     Bulgaria      6\n",
       "1    Albania       Greece     12\n",
       "2    Albania         Ussr      5\n",
       "3    Algeria        Italy      5\n",
       "4    Algeria      Morocco      6\n",
       "5     Angola   Cape Verde      6\n",
       "6     Angola   Mozambique      6\n",
       "7  Australia       Canada      6\n",
       "8  Australia        Japan      5\n",
       "9  Australia  Philippines      6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relationships = []\n",
    "n = len(df_sentences_filtered)\n",
    "if n == 0:\n",
    "    print(\"No country co-occurrences found after normalization. Expand aliases or check text cleaning.\")\n",
    "else:\n",
    "    window = 5  # sentences\n",
    "    for i in range(n):\n",
    "        end_i = min(i + window, n - 1)\n",
    "        # flatten list of lists in the window\n",
    "        country_list = [ent for ents in df_sentences_filtered.loc[i:end_i, 'country_entities'] for ent in ents]\n",
    "\n",
    "        if not country_list:\n",
    "            continue\n",
    "\n",
    "        # remove immediate duplicates to reduce noise\n",
    "        country_unique = [c for idx, c in enumerate(country_list) if idx == 0 or c != country_list[idx - 1]]\n",
    "\n",
    "        # record adjacent pairs in the window; sort pair so A-B == B-A\n",
    "        for a, b in zip(country_unique, country_unique[1:]):\n",
    "            pair = tuple(sorted((a, b)))\n",
    "            if pair[0] != pair[1]:  # skip self-pairs\n",
    "                relationships.append({\"source\": pair[0], \"target\": pair[1]})\n",
    "\n",
    "    relationships_df = pd.DataFrame(relationships)\n",
    "\n",
    "    if relationships_df.empty:\n",
    "        print(\"No pairs formed. Try a larger window or broaden aliases.\")\n",
    "    else:\n",
    "        # aggregate frequencies\n",
    "        relationships_df[\"value\"] = 1\n",
    "        relationships_df = relationships_df.groupby([\"source\", \"target\"], as_index=False)[\"value\"].sum()\n",
    "        display(relationships_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f2ee732-2127-4877-9cf1-7eda037af3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Poland</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italy</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Israel</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Israel</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Israel</td>\n",
       "      <td>Libya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iran</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source          target  value\n",
       "0  Albania        Bulgaria      1\n",
       "1    India        Pakistan      1\n",
       "2    Japan          Poland      1\n",
       "3    Japan     Philippines      1\n",
       "4    Italy  United Kingdom      1\n",
       "5    Italy           Japan      1\n",
       "6   Israel    South Africa      1\n",
       "7   Israel        Pakistan      1\n",
       "8   Israel           Libya      1\n",
       "9     Iran   United States      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# when creating relationships:\n",
    "relationships.append({\n",
    "    \"source\": min(a, b),\n",
    "    \"target\": max(a, b)\n",
    "})\n",
    "\n",
    "# Ensure strings, drop bad rows\n",
    "tmp = relationships_df[['source','target']].dropna().astype(str).copy()\n",
    "\n",
    "# Build sorted-pair key so A–B == B–A\n",
    "tmp['pair'] = tmp.apply(lambda r: tuple(sorted((r['source'], r['target']))), axis=1)\n",
    "\n",
    "# Count occurrences\n",
    "out = tmp.groupby('pair').size().reset_index(name='value')\n",
    "\n",
    "# Split pair back to two columns\n",
    "out[['source','target']] = pd.DataFrame(out['pair'].tolist(), index=out.index)\n",
    "out = out[['source','target','value']].sort_values('value', ascending=False).reset_index(drop=True)\n",
    "\n",
    "display(out.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea4960b3-2a67-4661-980d-ce4d1d71e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and export dataframe\n",
    "relationships_df.to_csv(\n",
    "    r\"C:\\Users\\moein\\20th-century\\data\\reference\\country_relationships.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63ff957-0ba1-43d7-bb20-949caad643bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (20th_century)",
   "language": "python",
   "name": "20th_century"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
